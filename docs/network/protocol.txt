
1、网络分层的真实含义

    只要是在网络上跑的包，都是完整的。可以有下层没上层，绝对不可能有上层没下层。
	
	
2、ifconfig命令

    查看ip地址命令：
	windows：ipconfig
	Linux：ifconfig 和 ip addr
	
	扩展知识： 
	ifconfig 和 ip addr 的区别
	ifconfig 是 net-tools 工具提供的命令
	ip addr 是 iproute2 工具提供的命令
	
	net-tools 和 iproute2 的区别
	net-tools起源于BSD，自2001年起，Linux社区已经对其停止维护，而iproute2旨在取代net-tools，并提供了一些新功能。
	一些Linux发行版已经停止支持net-tools，只支持iproute2。
    net-tools通过procfs(/proc)和ioctl系统调用去访问和改变内核网络配置，而iproute2则通过netlink套接字接口与内核通讯。
    net-tools中工具的名字比较杂乱，而iproute2则相对整齐和直观，基本是ip命令加后面的子命令。
    虽然取代意图很明显，但是这么多年过去了，net-tool依然还在被广泛使用，最好还是两套命令都掌握吧。
	
	IP 是地址，有定位功能；MAC 是身份证，无定位功能；
    CIDR 可以用来判断是不是本地人；
    IP 分公有的 IP 和私有的 IP。
	
	ip addr命令结果解析：
	----------------------------------------------------------------------------------
	[root@wx-test-116 ~]# ip addr
    1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
    2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP qlen 1000
    link/ether 00:50:56:b1:13:e1 brd ff:ff:ff:ff:ff:ff
    inet 10.126.3.116/24 brd 10.126.3.255 scope global eth0
	----------------------------------------------------------------------------------
	inet后面跟的是IP地址
	
	scope：
	对于 eth0 这张网卡来讲，是 global，说明这张网卡是可以对外的，可以接收来自各个地方的包。
	对于 lo 来讲，是 host，说明这张网卡仅仅可以供本机相互通信。
	lo 全称是loopback，又称环回接口，往往会被分配到 127.0.0.1 这个地址。这个地址用于本机通信，经过内核处理后直接返回，不会在任何网络中出现。
	
	link/ether 00:50:56:b1:13:e1 brd ff:ff:ff:ff:ff:ff这个被称为MAC 地址，是一个网卡的物理地址，用十六进制，6 个 byte 表示。
	
	< BROADCAST,MULTICAST,UP,LOWER_UP >这个叫作net_device flags，网络设备的状态标识。
	UP 表示网卡处于启动的状态；
	BROADCAST 表示这个网卡有广播地址，可以发送广播包；
	MULTICAST 表示网卡可以发送多播包；
	LOWER_UP 表示 L1 是启动的，也即网线插着呢。
	
	MTU1500 最大传输单元 MTU 为 1500，这是以太网的默认值。
	MTU 是二层 MAC 层的概念。MAC 层有 MAC 的头，以太网规定连 MAC 头带正文合起来，不允许超过 1500 个字节。
	正文里面有 IP 的头、TCP 的头、HTTP 的头。如果放不下，就需要分片来传输。
	
	qdisc mq 
	qdisc 全称是queueing discipline，中文叫排队规则。内核如果需要通过某个网络接口发送数据包，它都需要按照为这个接口配置的 qdisc（排队规则）把数据包加入队列。
	最简单的 qdisc 是 pfifo，它不对进入的数据包做任何的处理，数据包采用先入先出的方式通过队列。
	
	
3、DHCP与PXE

    手动配置ip地址
	
	使用 net-tools：
    $ sudo ifconfig eth1 10.0.0.1/24
    $ sudo ifconfig eth1 up
	
    使用 iproute2：
    $ sudo ip addr add 10.0.0.1/24 dev eth1
    $ sudo ip link set up eth1

	动态分配ip地址――动态主机配置协议（DHCP）
	只需要配置一段共享的 IP 地址。每一台新接入的机器都通过 DHCP 协议，来这个共享的 IP 地址里申请，然后自动配置好就可以了。
	等人走了，或者用完了，还回去，这样其他的机器也能用。
	
	DHCP 的工作方式：
	DHCP Discover --> DHCP Offer --> DHCP Request --> DHCP ACK
	
	预启动执行环境（Pre-boot Execution Environment），简称PXE。
	数据中心里面的管理员可能一下子就拿到几百台空的机器，一个个安装操作系统，会累死的。
    所以管理员希望的不仅仅是自动分配 IP 地址，还要自动安装系统。装好系统之后自动分配 IP 地址，直接启动就能用了，这样当然最好了！
	通过PXE可以实现上面的要求。
	

4、从物理层到MAC层

    第一层（物理层）：提供物理层联通方案
	
	两台电脑互连：
	物理层设备：一个有两个头的网线
	          注意：水晶头要做交叉线，用的就是所谓的1－3、2－6 交叉接法。
			  水晶头的第 1、2 和第 3、6 脚，它们分别起着收、发信号的作用。
			  将一端的 1 号和 3 号线、2 号和 6 号线互换一下位置，就能够在物理层实现一端发送的信号，另一端能收到。
	网络设置：配置这两台电脑的 IP 地址、子网掩码和默认网关
	
	三台电脑互连：
	物理层设备：集线器Hub
	            集线器没有大脑，它完全在物理层工作。它会将自己收到的每一个字节，都复制到其他端口上去。（广播模式）
	网络设置：配置这三台电脑的 IP 地址、子网掩码和默认网关
	
	第二层（数据链路层，即MAC层）
	解决三个问题：
	（1）这个包是发给谁的？谁应该接收？
    （2）大家都在发，会不会产生混乱？有没有谁先发、谁后发的规则？（多路访问问题）
    （3）如果发送的时候出现了错误，怎么办？
	
	问题（1）解决方案：
	    网络包中引入目标的 MAC 地址和源的 MAC 地址
	问题（2）解决方案：
	    方式一：分多个车道。每个车一个车道，你走你的，我走我的。这在计算机网络里叫作信道划分；
        方式二：今天单号出行，明天双号出行，轮着来。这在计算机网络里叫作轮流协议；
        方式三：不管三七二十一，有事儿先出门，发现特堵，就回去。错过高峰再出。我们叫作随机接入协议。著名的以太网，用的就是这个方式。
	问题（3）解决方案：
	    MAC头中引入CRC，也	就是循环冗余检测。通过 XOR 异或的算法，来计算整个包是否在发送的过程中出现了错误
		
	使用集线器连接多台电脑存在的问题：
	因为 Hub 是广播的，不管某个接口是否需要，所有的 Bit 都会被发送出去，然后让主机来判断是不是需要。
	这种方式路上的车少就没问题，车一多，产生冲突的概率就提高了。而且把不需要的包转发过去，纯属浪费。
	
	二层设备交换机，可以解决集线器存在的问题。
	交换机通过学习会记录一份转发表，通过转发表可以知道交换机每个口连接的电脑的MAC地址
	
	收到网络包，交换机可以从包中拿出MAC头，检查一下目标 MAC 地址，从转发表中找到该MAC地址对应的口，然后从此口转发到特定的电脑。
	

5、交换机与VLAN

    使用多个交换机可能会产生环路问题
	解决方案：STP（Spanning Tree Protocol） 协议
	
	如何解决广播问题和安全问题？
	（1）物理隔离
	     每个部门有单独的交换机，配置单独的子网，这样部门之间的沟通就需要路由器了。
	（2）虚拟隔离
	     虚拟隔离，就是用我们常说的VLAN，或者叫虚拟局域网。使用 VLAN，一个交换机上会连属于多个局域网的机器。
		 交换机怎么区分哪个机器属于哪个局域网呢？
		 只需要在原来的二层的头上加一个 TAG，里面有一个 VLAN ID，一共 12 位。为什么是 12 位呢？因为 12 位可以划分 4096 个 VLAN。
		 如果我们买的交换机是支持 VLAN 的，当这个交换机把二层的头取下来的时候，就能够识别这个 VLAN ID。
		 这样只有相同 VLAN 的包，才会互相转发，不同 VLAN 的包，是看不到的。这样广播问题和安全问题就都能够解决了。
		 
6、ICMP与ping：投石问路的侦察兵

    ping 是基于 ICMP 协议工作的。ICMP全称Internet Control Message Protocol，就是互联网控制报文协议。
	
	ICMP 报文是封装在 IP 包里面的。
	
	ICMP 相当于网络世界的侦察兵。两种类型的 ICMP 报文，一种是主动探查的查询报文，一种异常报告的差错报文；
    ping 使用查询报文，Traceroute 使用差错报文。
	
7、网关

    家庭路由器会有内网网口和外网网口。
   
    跨网关访问的时候，牵扯到 MAC 地址和 IP 地址的变化。
   
    在任何一台机器上，当要访问另一个 IP 地址的时候，都会先判断，这个目标 IP 地址，和当前机器的 IP 地址，是否在同一个网段。
    怎么判断同一个网段呢？需要 CIDR 和子网掩码。
   
    如果是同一个网段，那就没网关什么事情，直接将源地址和目标地址放入 IP 头中，然后通过 ARP 获得 MAC 地址，将源 MAC 和目的 MAC 放入 MAC 头中，发出去就可以了。
   
    如果不是同一网段，这就需要发往默认网关 Gateway。Gateway 的地址一定是和源 IP 地址是一个网段的。往往不是第一个，就是第二个。
    例如 192.168.1.0/24 这个网段，Gateway 往往会是 192.168.1.1/24 或者 192.168.1.2/24。

    网关往往是一个路由器，是一个三层转发的设备。
	啥叫三层设备？就是把 MAC 头和 IP 头都取下来，然后根据里面的内容，看看接下来把包往哪里转发的设备。
	
	很多情况下，人们把网关就叫作路由器。其实不完全准确，而另一种比喻更加恰当：路由器是一台设备，它有五个网口或者网卡，相当于有五只手，分别连着五个局域网。
	每只手的 IP 地址都和局域网的 IP 地址相同的网段，每只手都是它握住的那个局域网的网关。
	
	任何一个想发往其他局域网的包，都会到达其中一只手，被拿进来，拿下 MAC 头和 IP 头，看看，根据自己的路由算法，选择另一只手，加上 IP 头和 MAC 头，然后扔出去。
	
	静态路由：
	静态路由，其实就是在路由器上，配置一条一条规则。
	每当要选择从哪只手抛出去的时候，就一条一条的匹配规则，找到符合的规则，就按规则中设置的那样，从某个口抛出去，找下一跳 IPX。
	所谓的下一跳是，某个 IP 要将这个 IP 地址转换为 MAC 放入 MAC 头。
	
	MAC 地址是一个局域网内才有效的地址。因此，MAC 地址只要过网关，就必定会改变，因为已经换了局域网。
	
	过网关 IP 地址会不会变呢？
	不改变 IP 地址的网关，我们称为转发网关；
	改变 IP 地址的网关，我们称为NAT 网关。
	
	Network Address Translation，简称NAT。
	
8、路由

    *如何配置路由？
	
	路由器就是一台网络设备，它有多张网卡。
	当一个入口的网络包送到路由器时，它会根据一个本地的转发信息库，来决定如何正确地转发流量。这个转发信息库通常被称为路由表。
	
	一张路由表中会有多条路由规则。每一条规则至少包含以下三项信息：
    目的网络：这个包想去哪儿？
    出口设备：将包从哪个口扔出去？
    下一跳网关：下一个路由器的地址。
	
	通过 route 命令和 ip route 命令都可以进行查询或者配置。
	例如，我们设置 ip route add 10.176.48.0/20 via 10.173.32.1 dev eth0，就说明要去 10.176.48.0/20 这个目标网络，要从 eth0 端口出去，经过 10.173.32.1。
	这种配置方式的一个核心思想是：根据目的 IP 地址来配置路由。
	
	*如何配置策略路由？
	
	在真实的复杂的网络环境中，除了可以根据目的 ip 地址配置路由外，还可以根据多个参数来配置路由，这就称为策略路由。
	
	查看路由配置：ip route list table main 
	
	*动态路由算法
	
	使用动态路由路由器，可以根据路由协议算法生成动态路由表，随网络运行状况的变化而变化。
	
	距离矢量路由算法――基于 Bellman-Ford 算法。
	基本思路：
	每个路由器都保存一个路由表，包含多行，每行对应网络中的一个路由器，
	每一行包含两部分信息，一个是要到目标路由器，从哪条线出去，另一个是到目标路由器的距离。
	每个路由器都是知道全局信息的。那这个信息如何更新呢？每个路由器都知道自己和邻居之间的距离，
	每过几秒，每个路由器都将自己所知的到达所有的路由器的距离告知邻居，每个路由器也能从邻居那里得到相似的信息。
	存在的问题：
	第一个问题就是好消息传得快，坏消息传得慢。
	第二个问题是，每次发送的时候，要发送整个全局路由表。网络大了，谁也受不了，所以最早的路由协议 RIP 就是这个算法。它适用于小型网络（小于 15 跳）。
	
	链路状态路由算法――基于 Dijkstra 算法。
	基本思路：
	当一个路由器启动的时候，首先是发现邻居，向邻居 say hello，邻居都回复。
	然后计算和邻居的距离，发送一个 echo，要求马上返回，除以二就是距离。
	然后将自己和邻居之间的链路状态包广播出去，发送到整个网络的每个路由器。
	这样每个路由器都能够收到它和邻居之间的关系的信息。
	因而，每个路由器都能在自己本地构建一个完整的图，然后针对这个图使用 Dijkstra 算法，找到两点之间的最短路径。
	
	不像距离距离矢量路由协议那样，更新时发送整个路由表。
	链路状态路由协议只广播更新的或改变的网络拓扑，这使得更新信息更小，节省了带宽和 CPU 利用率。
	而且一旦一个路由器挂了，它的邻居都会广播这个消息，可以使得坏消息迅速收敛。
	
	*动态路由协议
	
	基于链路状态路由算法的 OSPF（Open Shortest Path First，开放式最短路径优先）
	广泛应用在数据中心中的协议。由于主要用在数据中心内部，用于路由决策，因而称为内部网关协议（Interior Gateway Protocol，简称IGP）。
	内部网关协议的重点就是找到最短的路径。在一个组织内部，路径最短往往最优。
	当然有时候 OSPF 可以发现多个最短的路径，可以在这多个路径中进行负载均衡，这常常被称为等价路由。
	
	基于距离矢量路由算法的 BGP（Border Gateway Protocol，简称BGP，外网路由协议）
	外网的路由协议，也即国家之间的，又有所不同。我们称为外网路由协议（Border Gateway Protocol，简称BGP）。
	在一个国家内部，有路当然选近的走。但是国家之间，不光远近的问题，还有政策的问题。
	对于网络包同样，每个数据中心都设置自己的 Policy。
	在网络世界，这一个个国家成为自治系统AS（Autonomous System）。
	在路径中将一个自治系统看成一个整体，不区分自治系统内部的路由器，这样自治系统的数目是非常有限的。
	就像大家都能记住出去玩，从中国出发先到韩国然后到日本，只要不计算细到具体哪一站，就算是发送全局信息，也是没有问题的。
	
9、传输层：TCP和UDP

    TCP和UDP有哪些区别？
	
	TCP是面向连接的，UDP是面向无连接的。
    ----------------------------------------------------------------------------------------- 
	面向连接的协议会在客户端和服务端之间开始传输数据前先建立连接。
	所谓的建立连接，是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态。
	-----------------------------------------------------------------------------------------
	
	TCP提供可靠交付。通过TCP连接传输的数据，无差错、不丢失、不重复、并且按序到达。
	UDP继承了IP的特性（没有任何可靠性保证），不保证不丢失，不保证按序到达。
	
	TCP是面向字节流的，发送的时候是一个流。
	UDP是面向数据报的。
	
	如果将 TCP 比作成熟的社会人，UDP 则是头脑简单的小朋友。TCP 复杂，UDP 简单；TCP 维护连接，UDP 谁都相信；TCP 会坚持知进退；UDP 愣头青一个，勇往直前；

    UDP 虽然简单，但它有简单的用法。它可以用在环境简单、需要多播、应用层自己控制传输的地方。例如 DHCP、VXLAN、QUIC 等。
	
10、TCP协议（上）

    建立连接：TCP 三次握手
	A请求->B应答->A应答之应答，保证双方的消息都有去有回。
	
	
	结束连接：TCP 四次挥手
	A结束->B应答->B结束->A应答
	
11、TCP协议（下）

    滑动窗口(rwnd)：解决顺序问题、丢包问题、流量控制
	
	    发送端数据结构
		―――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――
	                ---------------------------------
		发送已确认  |  发送未确认   |  未发送可发送  |    未发送不可发送
                    ---------------------------------
					|               |                |_
				LastByteAcked   LastByteSent           AdvertisedWindow
		―――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――
		接收端数据结构
		―――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――
		------------------------------------------------
		|       接收已确认      |     等待接收未确认   |   不能接收
		------------------------------------------------
		|                       |                      |_
		LastByteRead         NextByteExpected            MaxRcvBuffer
		―――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――
	
	拥塞窗口(cwnd)：拥塞控制
	
	滑动窗口 rwnd 是怕发送方把接收方缓存塞满，而拥塞窗口 cwnd，是怕把网络塞满。
	公式：LastByteSent - LastByteAcked <= min {cwnd, rwnd} 
	在理想状态下，对于到网络上，通道的容量 = 带宽 × 往返延迟。
	带宽，也即每秒钟能够发送多少数据
	
12 套接字Socket

    基于TCP 和 UDP协议的Socket编程：

    在通信之前，双方都要建立一个Socket。

    在建立Socket的时候需要设置参数：
    Socket编程是端到端的通信，往往意识不到中间要经过多少局域网，多少路由器，因而能够设置的参数，也只能是端到端协议上网络层和传输层的。
    在网络层，Socket函数需要指定到底是 IPv4 还是 IPv6，分别对应设置为 AF_INET 和 AF_INET6。另外，还要指定到底是 TCP 还是 UDP，TCP协议是
    基于数据流的，所以设置为 SOCK_STREAM，而UDP是基于数据报的，因为设置为 SOCK_DGRAM。

    基于TCP协议的Socket程序函数调用过程：
    （1）TCP服务端要先监听一个端口，一般是先调用 bind 函数，给这个Socket赋予一个IP地址和端口。
    （2）当服务端有了IP和端口号，就可以调用 listen 函数进行监听。在TCP的状态图里，有一个listen状态，当调用这个函数之后，服务端就进入了这个状态，
         这个时候客户端就可以发起连接了。
    （3）在内核中，为每个Socket维护两个队列。
         一个是已经建立了连接的队列，这时候连接三次握手已经完毕，处于established状态;
         一个是还没有完全建立连接的队列，这个时候三次握手还没有完成，处于syn_rcvd的状态。
         接下来，服务端调用 accept 函数，拿出一个已经建立完成的连接进行处理。如果还没有建立完成的连接，就要等着。
    （4）在服务器端等待的时候，客户端可以通过 connect 函数发起连接。先在参数中指明要连接的IP地址和端口号，然后开始发起三次握手。
         内核会给客户端分配一个临时的端口。一旦握手成功，服务端的accept就会返回另一个Socket。
         也就是说，监听的Socket和真正用来传数据的Socket是两个，一个叫作监听Socket，一个叫作已连接Socket。
    （5）连接建立成功之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。

         客户端             服务端
         socket()          socket()
            |                 |
            |               bind()
            |                 |
            |              listen() 
         connect()---|        |  
            |         -----accept()
          write()----|        |
            |         ----- read()
          read()-----|        |
                      ----- write()

    基于UDP协议的Socket程序函数调用过程
    UDP是没有连接的，所以不需要三次握手，也就不需要调用listen 和 connect，但是，UDP的交互仍然需要IP和端口号，因而也需要 bind。
    UDP是没有维护连接状态的，因而不需要每对连接建立一组Socket，而是只要有一个Socket，就能够和多个客户端通信。
    也正是因为没有连接状态，每次通信的时候，都调用 sendto 和 recvfrom，都可以传入IP地址和端口。
        
         客户端            服务端
         socket()         socket()
            |                |
          bind()           bind()
            |                |
         sendto()   ----  recvfrom()
            |                |
         recvfrom() ----   sendto()

    服务器如何接更多的项目？
    方式一：将项目外包给其他公司（多进程方式）
    方式二：将项目转包给独立的项目组（多线程方式）
    方式三：一个项目组支撑多个项目（IO多路复用，一个线程维护多个Socket）       select
    方式四：一个项目组支撑多个项目（IO多路复用，从“派人盯着”到“有事通知”）     epoll
 
13 HTTP协议

    以访问 http://www.163.com/ 为例，http://www.163.com/ 被称为 URL，统一资源定位符，其中http称为协议，www.163.com称为域名。
    
    HTTP请求的准备
    （1）浏览器将 www.163.com 这个域名发送给DNS服务器，让它解析为IP地址。
    （2）因为HTTP是基于TCP协议的，所以要先建立TCP连接（三次握手）。
         目前使用的HTTP协议大部分都是1.1，在1.1协议里，默认是开启了Keep-Alive的，这样建立的TCP连接，就可以在多次请求中复用。
    
    HTTP请求的构建
    建立TCP连接以后，浏览器就要发送HTTP请求。
    HTTP请求格式如下：
    -----------------------------------------------------
    请求行    | 方法 | sp | URL | sp | 版本 | cr | lf |
    首部      | 首部字段名： | sp | 字段值 | cr | lf |
              | cr | lf |
    实体      |                                       | 
    -----------------------------------------------------
    说明：HTTP 的报文大概分为三大部分。第一部分是请求行，第二部分是请求的首部，第三部分才是请求的正文实体。
    
    HTTP响应的构建
    HTTP响应报文也是有一定格式的，这也是基于HTTP1.1的。
    -------------------------------------------------------
    状态行    | 版本 | sp | 状态码 | sp | 短语 | cr | lf |
    首部      | 首部字段名：| sp | 字段值 | cr | lf |
              | cr | lf |
    实体      |                                          |
    -------------------------------------------------------
	
14 HTTPS协议

    加密，分为对称加密 和 非对称加密。

    对称加密：
    加密和解密使用的密钥是相同的。
    也就是说，加密和解密使用的是同一个密钥。
    因此，对称加密算法要保证安全的话，密钥要做好保密。
    只能让使用的人知道，不能对外公开。

    非对称加密：
    加密使用的密钥和解密使用的密钥是不相同的。
    一把是做为公开的公钥，另一把是作为谁都不能给的私钥。
    公钥加密的信息，只有私钥才能解密。私钥加密的信息,只有公钥才能解密。

    因为对称加密算法相比非对称加密算法来说，效率要高得多，性能也好，所以交互场景下多用对称加密。
    
    使用对称加密，存在的问题是：无法安全的传输密钥。为了解决这个问题，就需要非对称加密的介入。
 
    服务端 和 客户端 分别有各自的一对公钥和私钥，并且都把自己的公钥公布给对方，
    服务端给客户端发送消息前先使用客户端的公钥加密，而客户端给服务端发消息前先使用服务端的公钥加密。

    使用非对称加密，存在的问题是：如何鉴别别人给你的公钥是对的，不是冒充的？因为每个人都可以创建自己的公钥和私钥。

    例如，为网站zhuyca创建私钥：
    $ openssl genrsa -out zhuycaprivate.key 1024
    然后，在根据这个私钥，创建对应的公钥：
    $ openssl rsa -in zhuycaprivate.key -pubout -out zhuycapublic.pem

    数字证书：
    为了鉴别公钥的真实可靠性，就需要权威部门的介入，由权威部门颁发一个证书，证书里包含：公钥/所有者/发布机构/有效期。

    数字证书是怎么生成的？
    生成证书需要发起一个证书请求，然后将这个请求发给一个权威机构去认证，这个权威机构我们称为CA（Certificate Authority）。
    
    证书请求可以通过以下命令生成：
    $ openssl req -key zhuycaprivate.key -new -out zhuycacertificate.req
    
    将这个请求发给权威机构，权威机构会给这个证书卡一个章，我们称为签名算法。
    那么问题是：怎么保证是真的权威机构签名的呢？
    答案是：只有用只掌握在权威机构手里的东西签名才行，这就是CA的私钥。

    签名算法的工作过程大概是：一般是对信息做一个Hash计算，得到一个Hash值，这个过程是不可逆的，也就是说无法通过Hash值得出原来的信息内容。
    在把信息发送出去之前，先把这个Hash值使用私钥加密后，作为一个签名，和信息一起发出去。   
	
	权威机构给证书签名的命令：
	$ openssl x509 -req -in zhuycacertificate.req -CA cacertificate.pem -CAkey caprivate.key -out zhuycacertificate.pem
	这个命令会返回 Signature ok，而 cliu8sitecertificate.pem 就是签过名的证书。
	
	查看证书内容命令：
	$ openssl x509 -in zhuycacertificate.pem -noout -text
	其中： Issuer，也即证书是谁颁发的；
	       Subject，就是证书颁发给谁；
		   Validity 是证书期限；
		   Public-key 是公钥内容；
		   Signature Algorithm 是签名算法。
		   
	CA 是分等级的，类似于 区公安局-市公安局这样，如果你对区公安局不信任，可以继续向市公安局查询。
	全球皆知的几个著名大 CA，称为root CA。
	也就是说，CA的公钥，由它的上级CA颁发签名证书，上级CA的公钥再由上上级CA颁发签名证书，直到root CA为止。
	通过这种层层授信背书的方式，从而保证了非对称加密模式的正常运转。
	
	HTTPS 的工作模式
	HTTPS 的总体思路：公钥私钥主要用于传输对称加密的秘钥，而真正的双方大数据量的通信都是通过对称加密进行。
	
15、流媒体协议 （如直播）

    无论是点播还是直播，其实都是对于视频数据的传输。
	
	视频技术的三个名词系列：
	名词系列一：AVI、MPEG、RMVB、MP4、MOV、FLV、WebM、WMV、ASF、MKV
	名词系列二：H.261、H.262、H.263、H.264、H.265
	名词系列三：MPEG-1、MPEG-2、MPEG-4、MPEG-7
	
	视频是什么？
	视频，其实就是快速播放一连串连续的图片。
	每一张图片，我们称为一帧。
	只要每秒钟帧的数据足够多，也即播放的足够快，比如每秒30帧，以人的眼睛的敏感程度，是看不出这是一张张独立的图片的，这就是我们常说的帧率（FPS）。
	
	每一张图片，都是由像素组成的，假设为 1024 * 768. 每个像素由RGB组成，每个8位，共24位。
	
	计算每秒钟的视频大小：
	30 帧 * 1024 * 768 * 24 = 566,231,040Bits = 70,778,880Bytes 
	一分钟的话就是：4,246,732,800Bytes，已经是 4 个 G 了。
	这么大的数据量 存储和传输都是个问题，所以视频数据需要编码，也就是压缩。
	
	之所以能够对视频流中的图片进行压缩，因为视频和图片有这样一些特点：
	（1）空间冗余：图像的相邻像素之间有较强的相关性，一张图片相邻像素往往是渐变的，不是突变的，没必要每个像素都完整地保存，
	               可以隔几个保存一个，中间的用算法计算出来。
    （2）时间冗余：视频序列的相邻图像之间内容相似。一个视频中连续出现的图片也不是突变的，可以根据已有的图片进行预测和推断。
    （3）视觉冗余：人的视觉系统对某些细节不敏感，因此不会每一个细节都注意到，可以允许丢失一些数据。
    （4）编码冗余：不同像素值出现的概率不同，概率高的用的字节少，概率低的用的字节多，类似霍夫曼编码（Huffman Coding）的思路。
	
	视频编码分两大流派：
	流派一：ITU（International Telecommunications Union）的 VCEG（Video Coding Experts Group），这个称为国际电联下的 VCEG。
	        既然是电信，可想而知，他们最初做视频编码，主要侧重传输。名词系列二，就是这个组织制定的标准。
	流派二：ISO（International Standards Organization）的 MPEG（Moving Picture Experts Group），这个是ISO 旗下的 MPEG，本来是做视频存储的。
	        例如，编码后保存在 VCD 和 DVD 中。当然后来也慢慢侧重视频传输了。名词系列三，就是这个组织制定的标准。
			
	后来，ITU-T（国际电信联盟电信标准化部门，ITU Telecommunication Standardization Sector）与 MPEG 联合制定了 H.264/MPEG-4 AVC.
	
	经过编码之后，生动活泼的一帧一帧的图像，就变成了一串串让人看不懂的二进制，这个二进制可以放在一个文件里面，按照一定的格式保存起来，这就是名词系列一。
	
	网络直播的工作原理？
	这个二进制也可以通过某种网络协议进行封装，放在互联网上传输，这个时候就可以进行网络直播了。
	网络协议将编码好的视频流，从主播端推送到服务器，这个过程称为【推流】，
	在服务器上有个运行了同样协议的服务端来接收这些网络包，从而得到里面的视频流，这个过程称为【接流】。
    服务端接到视频流之后，可以对视频流进行一定的处理，例如转码，也即从一个编码格式，转成另一种格式。因为观众使用的客户端千差万别，要保证他们都能看到直播。
    流处理完毕之后，就可以等待观众的客户端来请求这些视频流。观众的客户端请求的过程称为【拉流】。

    如果有非常多的观众，同时看一个视频直播，那都从一个服务器上拉流，压力太大了，因而需要一个视频的分发网络，将视频预先加载到就近的边缘节点，
	这样大部分观众看的视频，是从边缘节点拉取的，就能降低服务器的压力。
	---------------------------------------------------------------------
	    主播       采样-->编码-->推流
                                   |
		服务端                   接流-->流处理-->分发
								                   |
		观众									  拉流-->解码-->播放
	----------------------------------------------------------------------
    
	编码：
	
	视频序列分成三种帧：
    I 帧，也称关键帧。里面是完整的图片，只需要本帧数据，就可以完成解码。
    P 帧，前向预测编码帧。P 帧表示的是这一帧跟之前的一个关键帧（或 P 帧）的差别，解码时需要用之前缓存的画面，叠加上和本帧定义的差别，生成最终画面。
    B 帧，双向预测内插编码帧。B 帧记录的是本帧与前后帧的差别。要解码 B 帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的数据与本帧数据的叠加，
	取得最终的画面。
	
	一个视频，可以拆分成一系列的帧，每一帧拆分成一系列的片，每一片都放在一个 NALU 里面，NALU 之间都是通过特殊的起始标识符分隔，
	在每一个 I 帧的第一片前面，要插入单独保存 SPS 和 PPS 的 NALU，最终形成一个长长的 NALU 序列。
	
	推流：
	直播端通过RTMP 协议 推流
	RTMP 是基于 TCP 的，因而肯定需要双方建立一个 TCP 的连接。
	在有 TCP 的连接的基础上，还需要建立一个 RTMP 的连接，也即在程序里面，你需要调用 RTMP 类库的 Connect 函数，显示创建一个连接。
	
	拉流：
	客户端通过 RTMP 协议 拉流
	
	先读到的是 H.264 的解码参数，例如 SPS 和 PPS，然后对收到的 NALU 组成的一个个帧，进行解码，交给播发器播放，一个绚丽多彩的视频画面就出来了。

16、P2P协议 (文件下载)

    网络下载文件都有哪些方式？
	------------------------------------------------------------------------------------------------------------------------------------------------
	HTTP 下载
	最简单的就是通过HTTP进行下载，也就是浏览器直接下载，问题是只要文件稍微大些，下载速度特别慢。
	------------------------------------------------------------------------------------------------------------------------------------------------
	FTP 下载
	FTP，即文件传输协议。
	FTP采用两个TCP连接来传输一个文件：控制连接 和 数据连接。
	FTP有两种工作模式：主动模式 和 被动模式 （站在FTP服务器角度来说）
	主动模式：客户端随机打开一个大于 1024 的端口 N，向服务器的命令端口 21 发起连接，同时开放 N+1 端口监听，并向服务器发出 “port N+1” 命令，
	          由服务器从自己的数据端口 20，主动连接到客户端指定的数据端口 N+1。
    被动模式：当开启一个 FTP 连接时，客户端打开两个任意的本地端口 N（大于 1024）和 N+1。第一个端口连接服务器的 21 端口，提交 PASV 命令。
	          然后，服务器会开启一个任意的端口 P（大于 1024），返回“227 entering passive mode”消息，里面有 FTP 服务器开放的用来进行数据传输的端口。
			  客户端收到消息取得端口号之后，会通过 N+1 号端口连接服务器的端口 P，然后在两个端口之间进行数据传输。
	------------------------------------------------------------------------------------------------------------------------------------------------
	P2P 下载
	为什么会有P2P？
	无论是 HTTP 的方式，还是 FTP 的方式，都有一个比较大的缺点，就是难以解决单一服务器的带宽压力， 因为它们使用的都是传统的客户端服务器的方式。
	后来，一种创新的、称为 P2P 的方式流行起来。P2P就是peer-to-peer。资源开始并不集中地存储在某些设备上，而是分散地存储在多台设备上。这些设备我们姑且称为 peer。
	
	为什么P2P可以解决单一服务器带宽压力？
	想要下载一个文件的时候，你只要得到那些已经存在了文件的 peer，并和这些 peer 之间，建立点对点的连接，而不需要到中心服务器上，就可以就近下载文件。
	一旦下载了文件，你也就成为 peer 中的一员，你旁边的那些机器，也可能会选择从你这里下载文件，所以当你使用 P2P 软件的时候，例如 BitTorrent，往往能够看到，
	既有下载流量，也有上传的流量，也即你自己也加入了这个 P2P 的网络，自己从别人那里下载，同时也提供给其他人下载。
	可以想象，这种方式，参与的人越多，下载速度越快，一切完美。
	
	种子（.torrent）文件
	当你想下载一个文件的时候，怎么知道哪些 peer 有这个文件呢？
    这就用到种子啦，也即咱们比较熟悉的.torrent 文件。.torrent 文件由两部分组成，分别是：announce（tracker URL）和文件信息。
	
	下载时，BT 客户端首先解析.torrent 文件，得到 tracker 地址，然后连接 tracker 服务器。
	tracker 服务器回应下载者的请求，将其他下载者（包括发布者）的 IP 提供给下载者。
	下载者再连接其他下载者，根据.torrent 文件，两者分别告知对方自己已经有的块，然后交换对方没有的数据。
	此时不需要其他服务器参与，并分散了单个线路上的数据流量，因此减轻了服务器的负担。
	
	从这个过程也可以看出，这种方式特别依赖 tracker。
	tracker 需要收集下载者信息的服务器，并将此信息提供给其他下载者，使下载者们相互连接起来，传输数据。
	虽然下载的过程是非中心化的，但是加入这个 P2P 网络的时候，都需要借助 tracker 中心服务器，这个服务器是用来登记有哪些用户在请求哪些资源。
    所以，这种工作方式有一个弊端，一旦 tracker 服务器出现故障或者线路遭到屏蔽，BT 工具就无法正常工作了。
	
	去中心化网络（DHT，Distributed Hash Table）
	为了实现彻底去中心化，后来就有了一种叫作DHT（Distributed Hash Table）的去中心化网络。
	每个加入这个 DHT 网络的人，都要负责存储这个网络里的资源信息和其他成员的联系信息，相当于所有人一起构成了一个庞大的分布式存储数据库。
	
	有一种著名的 DHT 协议，叫Kademlia 协议。
	
17、DNS协议：网络世界的地址簿

    DNS服务器
	
	在网络世界里，你肯定记得住网站的名称，但是很难记住网站的IP地址，因而需要一个地址簿，就是DNS服务器。
	
	每个人上网都需要访问DNS服务器，因而，DNS服务器，一定要设置成高可用、高并发和分布式的。
	
	为了实现高可用、高并发和分布式，DNS服务器设计成了树状的层次结构。
	------------------------------------------------------------------------------------------------------------------------------------------
	
	                               根DNS                                                根DNS服务器：返回顶级域DNS服务器的IP地址         老大
								     |
	            ------------------------------------------------
				|             |              |                 |
			  .com           .cn            .net              ...                       顶级域DNS服务器：返回权威DNS服务器的IP地址       老二
			    |             |              |                 
             -------        -------       -------  				
	         |     |        |     |       |     |
           163.com ... google.cn ...  csdn.net  ... 			                        权威DNS服务器：返回相应主机的IP地址              老三
	
	-------------------------------------------------------------------------------------------------------------------------------------------
	
	DNS 解析流程
	
	为了提高DNS的解析性能，很多网络会就近部署DNS缓存服务器。于是，就有了以下的DNS解析流程：
	（1）电脑客户端会发出一个DNS请求，问www.163.com的IP是啥，并发给本地域名服务器（本地DNS）。
	     什么是本地DNS？
		 如果是通过DHCP配置，本地DNS由你的网络服务商（ISP），如电信、移动等自动分配，它通常就在你网络服务商的某个机房。
	（2）本地DNS收到来自客户端的请求。
	     可以想象本地DNS上缓存了一张域名与之对应IP地址的大表格。
		 如果能找到www.163.com，它就直接返回IP地址。
         如果没有，本地DNS会去问它的根域名服务器：“老大，能告诉我www.163.com的IP地址吗？”
         根域名服务器是最高层次的，全球共有13套。它不直接用于域名解析，但能指明一条道路。
    （3）根DNS收到来自本地DNS的请求，发现后缀是.com，说：“哦，www.163.com啊，这个域名是由.com区域管理，我给你它的顶级域名服务器的地址，你去问问它吧。“
    （4）本地DNS转向问顶级域名服务器：“老二，你能告诉我www.163.com的IP地址吗？”
         顶级域名服务器就是大名鼎鼎的比如.com、.net、.org这些一级域名，它负责管理二级域名，比如163.com，所以它能提供一条更清晰的方向。
    （5）顶级域名服务器说：“我给你负责www.163.com区域的权威DNS服务器的地址，你去问它应该能问到。”
    （6）本地DNS转向问权威DNS服务器：“老三，www.163.com对应的IP是啥？”
         163.com的权威DNS服务器，它是域名解析结果的原出处。为啥叫权威？就是我的域名我做主。	
	（7）权威DNS服务器查询后将对应的IP地址告诉本地DNS。
	（8）本地DNS再将IP地址返回客户端，客户端和目标建立连接。
	
	负载均衡
	
	在域名解析过程中，DNS除了可以把名称映射为IP地址，它还可以做另外一件事，就是负载均衡。
	
	DNS负载均衡可以分为：内部负载均衡 和 全局负载均衡。
	
	DNS 做内部负载均衡：
	
	例1：
	一个应用要访问数据库，在这个应用里面应该配置这个数据库的域名，而不是数据库的IP地址。
	这样如果有多个应用都配置了这台数据库的话，一旦数据库由于某种原因，换到了另一台机器上，也就是数据库IP地址换了，只需要在DNS服务器里，
	将域名映射为新的IP地址，各个应用配置都不需要做任何修改，大大简化了运维。
	例2：
	在例1的基础上，我们可以更进一步。
	例如，某个应用要访问另一个应用，如果配置另外一个应用的IP地址，那个这个访问就是一对一的。
	但是当被访问的应用撑不住的时候，我们其实可以部署多个。
	但是，访问它的应用如何在多个之间进行负载均衡？只要配置成为域名就可以了。
	在域名解析的时候，我们只要配置策略，这次返回第一个IP，下次返回第二个IP，就可以实现负载均衡了。
	
	DNS 做全局负载均衡：
	
	为了保证我们的应用高可用，往往会部署在多个机房，每个地方都会有自己的IP地址。
	当用户访问某个域名的时候，可以轮询访问多个数据中心。如果一个数据中心因为某种原因挂了，只要在DNS服务器里面，将这个数据中心对应的IP地址删除，
	这样就可以实现一定的高可用。
	
	另外，我们肯定希望北京的用户访问北京的数据中心，上海的用户访问上海的数据中心，这样，客户体验就会非常好，访问速度就会超快。这就是全局负载均衡的概念。
	
	对于不需要做全局负载均衡的简单应用来说，yourcompany.com的权威DNS服务器可以直接将object.yourcompany.com这个域名解析为一个或多个IP地址，然后客户端可以
	通过多个IP地址，进行简单的轮询，实现简单的负载均衡。
	
	但是对于复杂的应用，尤其是跨地域跨运营商的大型应用，则需要更加复杂的全局负载均衡机制，因而需要专门的设备或者服务器来做这件事情，这就是全局负载均衡器
	（GSLB，Global Server Load Balance）
	
	在yourcompany.com 的DNS服务器中，一般是通过配置CNAME的方式，给object.yourcompany.com起一个别名，例如object.vip.yourcompany.com 然后告诉本地DNS服务器，
	让它请求GSLB解析这个域名，GSLB就可以在解析这个域名的过程中，通过自己的策略实现负载均衡。
	
18 HTTPDNS

    传统DNS存在的问题？
    （1）域名缓存问题。
         缓存刷新不及时;
         有可能会使得全局负载均衡失效
    （2）域名转发问题。
         A运营商将请求转发给B运营商，B运营商去查权威DNS，权威NDS就会认为请求的客户来自B运营商。导致跨运营商访问，速度很慢。
    （3）出口NAT问题。
         配置网关出口时，很多机房都会配置NAT，使得从这个网关出去的包，都换成新的IP地址，当请求返回的时候，在这个网关，再把IP地址转换回去。
         此时，权威DNS服务器，就无法通过这个地址，来判断客户到底是来自哪个运营商，误判，导致跨运营商的访问。	
    （4）域名更新问题。
    （5）解析延迟问题。

    HTTPDNS
    HTTPDNS其实就是，不走传统的DNS解析，而是自己搭建基于HTTP协议的NDS服务器集群，分布在多个地点和多个运营商。当客户需要NDS解析的时候，直接
    通过HTTP协议进行请求这个服务器集群，得到就近的地址。

    这就相当于每家基于HTTP协议，自己实现自己的域名解析，自己做一个自己的地址簿，而不使用统一的地址簿。但是默认的域名解析都是走DNS的，因而
    使用HTTPDNS需要绕过默认的DNS路径，就不能使用默认的客户端。使用HTTPDNS的，往往是手机应用，需要在手机端嵌入支持HTTPDNS的客户端SDK。
	
19、CDN

    CDN分发系统架构
    
    全球有很多数据中心，无论在哪里上网，临近不远的地方基本上都有数据中心。
    可以在这些数据中心里部署几台机器，形成一个缓存的集群来缓存部分数据，那么用户访问的时候，就可以就近访问了。
    这些分布在各个地方的各个数据中心的节点，就称为边缘节点。

    由于边缘节点数目比较多，但是每个集群规模比较小，不可能缓存下来所有东西，因而可能无法命中；这样就会在边缘节点之上有区域节点。
    区域节点，较边缘节点，规模更大，缓存数据更多，命中率更大。在区域节点之上是中心节点。
    中心节点，较区域节点，规模更大，缓存数据更多，命中率更大。
    如果中心节点还不能够命中的话，就只好回源网站访问了。

                                            中心节点
                                                |
                                    --------------------------
                                    |           |             |
                                区域节点     区域节点      区域节点 
                                    |
                              -------------
                             |      |      |
                        边缘节点  边缘节点 边缘节点			

    客户端如何找到相应的边缘节点进行访问？
    
    思路类似于基于DNS的全局负载均衡。

    在没有CDN的情况下，用户向浏览器输入www.web.com这个域名，客户端访问本地DNS服务器的时候，如果本地DNS服务器有缓存，则返回网站的地址；
	如果没有，递归查询到网站的权威DNS服务器，这个权威DNS服务器是负责web.com的，它会返回网站的IP地址。本地DNS服务器缓存下IP地址，将IP
	地址返回，然后客户端直接访问这个IP地址，就访问到了这个网站。
	
	有了CDN，情况就发生了变化。在web.com这个权威DNS服务器上，会设置一个CNAME别名，指向另外一个域名www.web.cdn.com，返回给本地DNS服务器。
	
	当本地DNS服务器拿到这个新的域名时，需要继续解析这个新的域名。这个时候，再访问的就不是web.com的权威DNS服务器了，而是web.cdn.com的
	权威DNS服务器，这是CDN自己的权威DNS服务器。在这个服务器上，还是会设置一个CNAME，指向另一个域名，也即CDN网络的全局负载均衡器。
	
	接下来，本地DNS服务器取请求CDN的全局负载均衡器解析域名，全局负载均衡器会为用户选择一台合适的缓存服务器提供服务，选择的依据包括：
	（1）根据用户IP地址，判断哪一台服务器距离用户最近；
	（2）用户所处的运营商；
	（3）根据用户所请求的URL中携带的内容名称，判断哪一台服务器上有用户所需的内容；
	（4）查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力。
	基于以上条件，进行综合分析之后，全局负载均衡器会返回一台缓存服务器的IP地址。
	
	本地DNS服务器缓存这个IP地址，然后将IP返回给客户端，客户端去访问这个边缘节点，下载资源。
	
	缓存服务器响应用户请求，将用户所需内容传送到用户终端。如果这台缓存服务器上并没有用户想要的内容，那么这台服务器就要向它的上一级缓存服务器
	请求内容，直到追溯到网站的源服务器将内容拉取到本地。
	
	重点：
	（1）CDN 和电商系统的分布式仓储系统一样，分为中心节点、区域节点、边缘节点，而数据缓存在离用户最近的位置。
	（2）CDN 最擅长的是缓存静态数据，除此之外还可以缓存流媒体数据，这时候要注意使用防盗链。
	     它也支持动态数据的缓存，一种是边缘计算的生鲜超市模式，另一种是链路优化的冷链运输模式。
		 
20、数据中心

    数据中心里面有一大堆电脑（服务器），这些服务器被放在一个个叫做机架（Rack）的架子上面。
	
	数据中心的入口和出口也是路由器，由于在数据中心的边界，成为边界路由器（Border Router）。为了高可用，边界路由器可以有多个。
	
	数据中心的边界路由器会连接多个运营商网络，这样做是为了高可用，一个运营商出现问题时，还可以通过另一个运营商来提供服务。
	
	数据中心往往有非常多的机器，当塞满一个机架的时候，需要有交换机将这些服务器连接起来，可以互相通信。这些交换机往往放在机架顶端，
	称为TOR（Top Of Rack）交换机。这一层的交换机常常称为接入层（Access Layer）。
	
	一个机架放不下的时候，就需要有多个机架，这时候就需要另外一种交换机将多个机架连接在一起。这种交换机性能更高、带宽更大。
	这种交换机称为汇聚层交换机（Aggregation Layer）。
	
	数据中心的每一个连接都需要考虑高可用。
	
	首先要考虑的是，如果一台机器只有一个网卡，上面连着一个网线，接入到TOR交换机上。如果网卡坏了，或者不小心网线掉了，机器就上不去了。
	所以需要至少两个网卡、两根网线插到TOR交换机上，但是两个网卡要工作的像一张网卡一样，这就是常说的网卡绑定（bound）。
	这就需要服务器和交换机都支持一种协议，LACP（Link Aggregation Control Protocol）。它们互相通信，将多个网卡聚合成为一个网卡，
	多个网线聚合成一个网线，在网线之间可以进行负载均衡，也可以为了高可用做准备。
	
	TOR交换机，接入层和汇聚层的连接也都需要高可用。最传统的方法是，部署两个接入交换机、两个汇聚交换机。
	
21、VPN

22、移动网络

	
	
	
	
	
	
	
	
	
	
	
	
	
	
