
* 架构设计的关键思维是判断和取舍，程序设计的关键思维是逻辑和实现。

========================================================================================================================================================
                       第一部分：架构设计基础：架构设计起源、架构设计的目的、常见架构复杂度分析、架构设计原则、架构设计流程
========================================================================================================================================================

1、架构是什么？

   架构是顶层设计；
   框架是面向编程或配置的半成品；
   组件是从技术维度上的复用；
   模块是从业务维度上职责的划分；
   系统是相互协同可运行的实体。
   
   框架关注的是“规范”，架构关注的是“结构”。
   框架的英文是 Framework，架构的英文是 Architecture。
   
   软件架构指软件系统的顶层结构：
   首先，“系统是一群关联个体组成”，这些“个体”可以是“子系统”“模块”“组件”等；架构需要明确系统包含哪些“个体”。
   其次，系统中的个体需要“根据某种规则”运作，架构需要明确个体运作和协作的规则。
   第三，维基百科定义的架构用到了“基础结构”这个说法，我改为“顶层结构”，可以更好地区分系统和子系统，避免将系统架构和子系统架构混淆在一起导致架构层次混乱。
   
2、架构设计历史背景

   软件架构的出现有其历史必然性。
   20 世纪 60 年代第一次软件危机引出了“结构化编程”，创造了“模块”概念；
   20 世纪 80 年代第二次软件危机引出了“面向对象编程”，创造了“对象”概念；
   到了 20 世纪 90 年代“软件架构”开始流行，创造了“组件”概念。
   我们可以看到，“模块”“对象”“组件”本质上都是对达到一定规模的软件进行拆分，差别只是在于随着软件的复杂度不断增加，拆分的粒度越来越粗，拆分的层次越来越高。
   
   一个成功的软件设计是要适应并满足业务需求，同时不断“演化”的。设计需要根据业务的变化、技术的发展不断进行“演进”，这就决定了这是一个动态活动，出现新问题，解决新问题，没有所谓的“一招鲜”。
   
   整个软件技术发展的历史，其实就是一部与“复杂度”斗争的历史，架构的出现也不例外
   
3、架构设计的目的
   
   架构设计的主要目的是为了解决软件系统复杂度带来的问题。
   
   通过熟悉和理解需求，识别系统复杂性所在的地方，然后针对这些复杂点进行架构设计。
   架构设计并不是要面面俱到，不需要每个架构都具备高性能、高可用、高扩展等特点，而是要识别出复杂点然后有针对性地解决问题。
   理解每个架构方案背后所需要解决的复杂点，然后才能对比自己的业务复杂点，参考复杂点相似的方案。

4 复杂度的来源――高性能

  （1）单台计算机内部为了高性能带来的复杂度
   手工操作―>批处理操作系统―>多进程（分时系统）―>多线程（分时系统）―>多CPU（真正并行）

   如果我们要完成一个高性能的软件系统，需要考虑如多进程、多线程、进程间通信、多线程并发等技术点，而且这些技术并不是最新的
   就是最好的，也不是非此即彼的选择。在做架构设计的时候，需要花费很大的精力来结合业务进行分析、判断、选择、组合，这个过程
   同样很复杂。  

  （2）多台计算机集群为了高性能带来的复杂度

   方式一：任务分配
          增加服务器，每个服务器上运行着相同的业务逻辑

          需要增加一个任务分配器
          任务分配器和真正的业务服务器之间有连接和交互
          任务分配器需要增加分配算法

   方式二：任务分解
          把一个大且复杂的业务系统，拆分成多个小而简单的业务系统，例如微信后台架构从逻辑上将业务进行了拆分，拆分成多个子业务，
          包括：接入/注册登陆/消息/摇一摇/漂流瓶/聊天/视频/朋友圈等，各个子业务系统单独部署到不同的服务器上，也就是说任务分解
          也增加了服务器数量，但是每个服务器上运行不同的业务逻辑
		  
5、复杂度的来源――高可用
         
    高可用：系统无中断地执行其功能的能力，代表系统的可用性程度，是进行系统设计时的准则之一。
	关键点：无中断
	系统高可用方案有很多，但本质上都是通过“冗余”来实现高可用。
    
	高可用的“冗余”解决方案，单纯从形式上来看，和高性能是一样的，都是通过增加更多机器来达到目的，但其实本质上是有根本区别的：
	高性能增加机器目的在于“扩展”处理性能；高可用增加机器目的在于“冗余”处理单元；
	
   （1）计算高可用
        
		任务分配
		        双机架构
				        主备：单纯的一台机器在跑流量，另一台机器实时地同步数据库，一旦主机宕机，备机立刻进入工作状态
						    冷备  冷备份服务器（cold server），平常情况下是关机状态，只有当主服务器宕机才开机
							温备  温备份服务器（warm server），周期性开机，根据主服务器内容进行更新，然后关机
							热备  热备份服务器（hot server），时刻处于开机状态，同主机保持同步，主机宕机时，可以随时启用热备份服务器
						主主：两台机都是同时工作，有真正做到负载均衡的作用
				集群架构（总数m + n）
				        m 主 n 备
   
   （2）存储高可用
   
        数据 + 逻辑 = 业务
		
		无论是正常情况下的传输延迟，还是异常情况下的传输中断，都会导致系统的数据在某个时间点或者时间段是不一致的，而数据的不一致又会导致业务问题；
		但如果完全不做冗余，系统的整体高可用又无法保证，所以存储高可用的难点不在于如何备份数据，而在于如何减少或者规避数据不一致对业务造成的影响。
		
	
	状态决策（高可用的基础）
	
	（1）独裁式
	     决策者：独立的决策主体，负责收集信息然后进行决策
		 上报者：所有其他冗余的个体，负责将状态信息发送给决策者
		 优点：因为只有一个决策者，所以不会出现决策混乱的问题
		 缺点：决策者本身故障时，整个系统就无法实现准确的状态决策
	
	（2）协商式
	     两个独立个体通过交流信息，然后根据规则进行决策，最常用的协商式决策就是主备决策。
		 这个架构的基本协商规则可以设计成：
         * 2 台服务器启动时都是备机。
         * 2 台服务器建立连接。
         * 2 台服务器交换状态信息。
         * 某 1 台服务器做出决策，成为主机；另一台服务器继续保持备机身份
		 优点：架构简单、规则也不复杂
		 缺点：主备连接中断时会出现决策错误
	
	（3）民主式
	     多个独立的个体通过投票的方式进行状态决策，多数取胜
		 缺点：可能会出现“脑裂”
		 
	无论采取什么样的方案，状态决策都不可能做到任何场景下都没有问题，但完全不做高可用方案又会产生更大的问题，如何选取适合系统的高可用方案，
	也是一个复杂的分析、判断和选择的过程。
	

6、复杂度的来源――可扩展性

    可扩展性 指系统为了应对将来需求变化而提供的一种扩展能力，当有新的需求出现时，系统不需要或者仅需要少量修改就可以支持，无须整个系统重构或者重建。

	设计具备良好可扩展性的系统，有两个基本条件：正确预测变化、完美封装变化。
	
	预测变化的复杂性在于：
    （1）不能每个设计点都考虑可扩展性。
    （2）不能完全不考虑可扩展性。
    （3）所有的预测都存在出错的可能性。
	
	对于架构师来说，如何把握预测的程度和提升预测结果的准确性，是一件很复杂的事情，而且没有通用的标准可以简单套上去，更多是靠自己的经验、直觉。
	
	应对变化的方案：
	方案一：将“变化”封装在一个“变化层”，将不变的部分封装在一个独立的“稳定层”。
	方案二：提炼出一个“抽象层”和一个“实现层”。抽象层是稳定的，实现层可以根据具体业务需要定制开发，当加入新的功能时，只需要增加新的实现，无须修改抽象层。
	
	
7 复杂度的来源――低成本/安全/规模

    *低成本
	
	当我们设计“高性能”“高可用”的架构时，通用的手段都是增加更多服务器来满足“高性能”和“高可用”的要求；
	而低成本正好与此相反，我们需要减少服务器的数量才能达成低成本的目标。
	因此，低成本本质上是与高性能和高可用冲突的，所以低成本很多时候不会是架构设计的首要目标，而是架构设计的附加约束。
	也就是说，我们首先设定一个成本目标，当我们根据高性能、高可用的要求设计出方案时，评估一下方案是否能满足成本目标，
	如果不行，就需要重新设计架构；如果无论如何都无法设计出满足成本要求的方案，那就只能找老板调整成本目标了。
	
	低成本给架构设计带来的主要复杂度体现在，往往只有“创新”才能达到低成本目标。
	这里的“创新”既包括开创一个全新的技术领域（这个要求对绝大部分公司太高），也包括引入新技术，
	如果没有找到能够解决自己问题的新技术，那么就真的需要自己创造新技术了。
	
	*安全
	
	从技术的角度来讲，安全可以分为两类：一类是功能上的安全，一类是架构上的安全。
	
	（1）功能安全
	常见的 XSS 攻击、CSRF 攻击、SQL 注入、Windows 漏洞、密码破解等
	本质上是因为系统实现有漏洞，黑客有了可乘之机。黑客会利用各种漏洞潜入系统，这种行为就像小偷一样，
	黑客和小偷的手法都是利用系统或家中不完善的地方潜入，并进行破坏或者盗取。因此形象地说，功能安全其实就是“防小偷”。
	
	从实现的角度来看，功能安全更多地是和具体的编码相关，与架构关系不大。
	
	很多开发框架都内嵌了常见的安全功能，能够大大减少安全相关功能的重复开发，但框架只能预防常见的安全漏洞和风险（常见的 XSS 攻击、CSRF 攻击、SQL 注入等），
	无法预知新的安全问题，而且框架本身很多时候也存在漏洞
	
	所以功能安全是一个逐步完善的过程，而且往往都是在问题出现后才能有针对性的提出解决方案，我们永远无法预测系统下一个漏洞在哪里，
	也不敢说自己的系统肯定没有任何问题。
	
	换句话讲，功能安全其实也是一个“攻”与“防”的矛盾，只能在这种攻防大战中逐步完善，不可能在系统架构设计的时候一劳永逸地解决。
	
	（2）架构安全
	如果说功能安全是“防小偷”，那么架构安全就是“防强盗”。强盗会直接用大锤将门砸开，或者用炸药将围墙炸倒；
	小偷是偷东西，而强盗很多时候就是故意搞破坏，对系统的影响也大得多。
	
	传统的架构安全主要依靠防火墙
	
	防火墙最基本的功能就是隔离网络，通过将网络划分成不同的区域，制定出不同区域之间的访问控制策略来控制不同信任程度区域间传送的数据流。
	
	防火墙的功能虽然强大，但性能一般，所以在传统的银行和企业应用领域应用较多。
	但在互联网领域，防火墙的应用场景并不多。因为互联网的业务具有海量用户访问和高并发的特点，防火墙的性能不足以支撑
	
	基于上述原因，互联网系统的架构安全目前并没有太好的设计手段来实现，更多地是依靠运营商或者云服务商强大的带宽和流量清洗的能力，较少自己来设计和实现。
	
	*规模
	
	规模带来复杂度的主要原因就是“量变引起质变”，当数量超过一定的阈值后，复杂度会发生质的变化。常见的规模带来的复杂度有：

   （1） 功能越来越多，导致系统复杂度指数级上升
       
	     系统的复杂度 = 功能数量 + 功能之间的连接数量
		 
		 例如，某个系统开始只有 3 大功能，后来不断增加到 8 大功能，虽然还是同一个系统，但复杂度已经相差很大了，具体相差多大呢？
		 假设系统间的功能都是两两相关：
		 3 个功能的系统复杂度 = 3 + 3 = 6
         8 个功能的系统复杂度 = 8 + 28 = 36
		 
   （2） 数据越来越多，系统复杂度发生质变
       
	     与功能类似，系统数据越来越多时，也会由量变带来质变，最近几年火热的“大数据”就是在这种背景下诞生的。
		 
		 目前的大数据理论基础是 Google 发表的三篇大数据相关论文，其中 
		 Google File System 是大数据文件存储的技术理论，
		 Google Bigtable 是列式数据存储的技术理论，
		 Google MapReduce 是大数据运算的技术理论，这三篇技术论文各自开创了一个新的技术领域。
		 
		 即使我们的数据没有达到大数据规模，数据的增长也可能给系统带来复杂性。
		 最典型的例子莫过于使用关系数据库存储数据，以 MySQL 为例，MySQL 单表的数据因不同的业务和应用场景会有不同的最优值，
		 但不管怎样都肯定是有一定的限度的，一般推荐在 5000 万行左右。如果因为业务的发展，单表数据达到了 10 亿行，就会产生很多问题
		 
		 因此，当 MySQL 单表数据量太大时，我们必须考虑将单表拆分为多表，这个拆分过程也会引入更多复杂性，例如：
		 拆表的规则是什么？
		 拆完表后查询如何处理？
		 
	
8、架构设计三原则

    *合适原则
	
	合适原则宣言：“合适优于业界领先”。
	真正优秀的架构都是在企业当前人力、条件、业务等各种约束下设计出来的，能够合理地将资源整合在一起并发挥出最大功效，并且能够快速落地。
	
	
	*简单原则
	
	简单原则宣言：“简单优于复杂”。
	“复杂”在制造领域代表先进，在建筑领域代表领先，但在软件领域，却恰恰相反，代表的是“问题”。
	
	软件领域的复杂性体现在两个方面：
	(1) 结构的复杂性
	结构复杂的系统几乎毫无例外具备两个特点：组成复杂系统的组件数量更多；同时这些组件之间的关系也更加复杂。
	
	结构上的复杂性存在的第一个问题是，组件越多，就越有可能其中某个组件出现故障，从而导致系统故障。
	    这个概率可以算出来，假设组件的故障率是 10%（有 10% 的时间不可用），那么
		有 3 个组件的系统可用性是（1-10%）×（1-10%）×（1-10%）= 72.9%，
		有 5 个组件的系统可用性是（1-10%）×（1-10%）×（1-10%）×（1-10%）×（1-10%）=59%，
		两者的可用性相差 13%。
	结构上的复杂性存在的第二个问题是，某个组件改动，会影响关联的所有组件，这些被影响的组件同样会继续递归影响更多的组件。
	    这个问题会影响整个系统的开发效率，因为一旦变更涉及外部系统，需要协调各方统一进行方案评估、资源协调、上线配合。
	结构上的复杂性存在的第三个问题是，定位一个复杂系统中的问题总是比简单系统更加困难。
	    首先是组件多，每个组件都有嫌疑，因此要逐一排查；
		其次组件间的关系复杂，有可能表现故障的组件并不是真正问题的根源。
		
	(2) 逻辑的复杂性
	逻辑复杂的组件，一个典型特征就是单个组件承担了太多的功能。
	
	结构的复杂性 和 逻辑的复杂性 需要达到一个平衡：
	为了降低结构复杂性，减少组件数量，那么单个组件的逻辑复杂性增高；为了降低逻辑复杂性，把复杂逻辑拆分到多个组件中，又增加了结构复杂性
	
	无论是结构的复杂性，还是逻辑的复杂性，都会存在各种问题，所以架构设计时如果简单的方案和复杂的方案都可以满足需求，最好选择简单的方案。
	
	《UNIX 编程艺术》总结的 KISS（Keep It Simple, Stupid!）原则一样适应于架构设计。
	
	
	*演化原则
	
	演化原则宣言：“演化优于一步到位”。
	
	软件架构需要根据业务发展不断变化。
	
	软件架构设计过程：
	首先，设计出来的架构要满足当时的业务需要。
    其次，架构要不断地在实际应用过程中迭代，保留优秀的设计，修复有缺陷的设计，改正错误的设计，去掉无用的设计，使得架构逐渐完善。
    第三，当业务发生变化时，架构要扩展、重构，甚至重写；代码也许会重写，但有价值的经验、教训、逻辑、设计等（类似生物体内的基因）却可以在新架构中延续。
	
	架构师在进行架构设计时需要牢记这个原则，时刻提醒自己不要贪大求全，或者盲目照搬大公司的做法。
	应该认真分析当前业务的特点，明确业务面临的主要问题，设计合理的架构，快速落地以满足业务需要，然后在运行过程中不断完善架构，不断随着业务演化架构。
	
	
10、架构设计流程第 1 步：识别复杂度

    架构设计的本质目的是为了解决软件系统的复杂性，所以在我们设计架构时，首先就要分析系统的复杂性。
	只有正确分析出了系统的复杂性，后续的架构设计方案才不会偏离方向；
	否则，如果对系统的复杂性判断错误，即使后续的架构设计方案再完美再先进，都是南辕北辙，做的越好，错的越多、越离谱。
	
	架构的复杂度主要来源于“高性能”“高可用”“可扩展”等几个方面，但架构师在具体判断复杂性的时候，不能生搬硬套，认为任何时候架构都必须同时满足这三方面的要求。
	实际上大部分场景下，复杂度只是其中的某一个，少数情况下包含其中两个，如果真的出现同时需要解决三个或者三个以上的复杂度，要么说明这个系统之前设计的有问题，
	要么可能就是架构师的判断出现了失误，即使真的认为要同时满足这三方面的要求，也必须要进行优先级排序。
	
	识别复杂度对架构师来说是一项挑战，因为原始的需求中并没有哪个地方会明确地说明复杂度在哪里，需要架构师在理解需求的基础上进行分析。
	有经验的架构师可能一看需求就知道复杂度大概在哪里；如果经验不足，那只能采取“排查法”，从不同的角度逐一进行分析。
	

11、架构设计流程第 2 步：设计备选方案

    经过架构设计第一步识别出复杂度后，就可以开始针对识别出的复杂度，设计备选方案。
	
    成熟的架构师需要对已经存在的技术非常熟悉，对已经经过验证的架构模式烂熟于心，然后根据自己对业务的理解，挑选合适的架构模式进行组合，
	再对组合后的方案进行修改和调整。
	
	虽然软件技术经过几十年的发展，新技术层出不穷，但是经过时间考验，已经被各种场景验证过的成熟技术其实更多。
	例如，高可用的主备方案、集群方案，高性能的负载均衡、多路复用，可扩展的分层、插件化等技术，
	绝大部分时候我们有了明确的目标后，按图索骥就能够找到可选的解决方案。

    只有当这种方式完全无法满足需求的时候，才会考虑进行方案的创新，而事实上方案的创新绝大部分情况下也都是基于已有的成熟技术。
	
	虽说基于已有的技术或者架构模式进行组合，然后调整，大部分情况下就能够得到我们需要的方案，但并不意味着架构设计是一件很简单的事情。
	因为可选的模式有很多，组合的方案更多，往往一个问题的解决方案有很多个；如果再在组合的方案上进行一些创新，解决方案会更多。
	因此，如何设计最终的方案，并不是一件容易的事情，这个阶段也是很多架构师容易犯错的地方。
	
	第一种常见的错误：设计最优秀的方案。
	    根据架构设计原则中“合适原则”和“简单原则“的要求，挑选合适自己业务、团队、技术能力的方案才是好方案
	第二种常见的错误：只做一个方案。
	    备选方案的数量以 3 ~ 5 个为最佳。
		备选方案的差异要比较明显。
		备选方案的技术不要只局限于已经熟悉的技术。
	第三种常见的错误：备选方案过于详细。
	    选阶段关注的是技术选型，而不是技术细节，技术选型的差异要比较明显。
		

12、架构设计流程的第 3 步：评估和选择备选方案

    步骤一：360 度环评
	    
		列出我们需要关注的质量属性点，然后分别从这些质量属性的维度去评估每个方案，再综合挑选适合当时情况的最优方案。
	
	    常见的方案质量属性点有：性能、可用性、硬件成本、项目投入、复杂度、安全性、可扩展性等。
	
	    在评估这些质量属性时，需要遵循架构设计原则 1“合适原则”和原则 2“简单原则”，避免贪大求全，基本上某个质量属性能够满足一定时期内业务发展就可以了。
	
	    遵循架构设计原则 3“演化原则”，避免过度设计、一步到位的想法。
	
	    通常情况下，如果某个质量属性评估和业务发展有关系（例如，性能、硬件成本等），需要评估未来业务发展的规模时，一种简单的方式是将当前的业务规模乘以 2 ~4 即可，
	    如果现在的基数较低，可以乘以 4；如果现在基数较高，可以乘以 2。
	
	步骤二：根据360 度环评结果选择备选方案
	
	    具体做法是按优先级选择，即架构师综合当前的业务发展情况、团队人员规模和技能、业务发展预测等因素，
	将质量属性按照优先级排序，首先挑选满足第一优先级的，如果方案都满足，那就再看第二优先级……以此类推。
	

13、架构设计流程第 4 步：详细方案设计

    简单来说，详细方案设计就是将方案涉及的 关键技术细节 给确定下来。
	
	*假如我们确定使用 Elasticsearch 来做全文搜索，那么就需要确定 Elasticsearch 的索引是按照业务划分，还是一个大索引就可以了；
	副本数量是 2 个、3 个还是 4 个，集群节点数量是 3 个还是 6 个等。

    *假如我们确定使用 MySQL 分库分表，那么就需要确定哪些表要分库分表，按照什么维度来分库分表，分库分表后联合查询怎么处理等。

    *假如我们确定引入 Nginx 来做负载均衡，那么 Nginx 的主备怎么做，Nginx 的负载均衡策略用哪个（权重分配？轮询？ip_hash？）等。
	
	答案：只需要简单根据这些技术的【适用场景】选择就可以了。
	

	
========================================================================================================================================================
                                                             第二部分：业界成熟的架构模式
========================================================================================================================================================

14、高性能数据库集群-方式一“读写分离”            分散数据库读写操作的压力
    
	读写分离原理
	读写分离的基本原理是将数据库读写操作分散到不同的节点上
	
	读写分离的基本实现
	（1）数据库服务器搭建主从集群，一主一从、一主多从都可以。
    （2）数据库主机负责读写操作，从机只负责读操作。
    （3）数据库主机通过复制将数据同步到从机，每台数据库服务器都存储了所有的业务数据。
    （4）业务服务器将写操作发给数据库主机，将读操作发给数据库从机。
	
	注意：
	这里用的是“主从集群”，而不是“主备集群”。“从机”的“从”可以理解为“仆从”，仆从是要帮主人干活的，“从机”是需要提供读数据的功能的；
	而“备机”一般被认为仅仅提供备份功能，不提供访问功能。所以使用“主从”还是“主备”，是要看场景的，这两个词并不是完全等同的。
	
	
	“读写分离”可能会引入的两个设计复杂度：主从复制延迟和分配机制
	
	复制延迟
	延迟时间内主从数据不一致，某些业务可能会出现问题，例如注册登录，用户注册（写主库）完立即登录（读从库），但是登录时提示“您还没有注册”
	
	解决主从复制延迟有几种常见的方法：
	（1）写操作后的读操作指定发给数据库主服务器
	     这种方式和业务强绑定，对业务的侵入和影响较大
	（2）读从机失败后再读一次主机
	     这就是通常所说的“二次读取”，二次读取和业务无绑定，只需要对底层数据库访问的 API 进行封装即可，实现代价较小，
		 不足之处在于如果有很多二次读取，将大大增加主机的读操作压力。
	（3）关键业务读写操作全部指向主机，非关键业务采用读写分离
	
    
	分配机制
	将读写操作区分开来，然后访问不同的数据库服务器，一般有两种方式：程序代码封装和中间件封装。
	
	程序代码封装：
	程序代码封装指在代码中抽象一个数据访问层（所以有的文章也称这种方式为“中间层封装”），实现读写操作分离和数据库服务器连接的管理。
	
	程序代码封装特点：
	（1）实现简单，而且可以根据业务做较多定制化的功能。
    （2）每个编程语言都需要自己实现一次，无法通用，如果一个业务包含多个编程语言写的多个子系统，则重复开发的工作量比较大。
    （3）故障情况下，如果主从发生切换，则可能需要所有系统都修改配置并重启。
	
	程序代码封装的开源实现方案：
	淘宝的 TDDL（Taobao Distributed Data Layer，外号: 头都大了）是比较有名的。
	它是一个通用数据访问层，所有功能封装在 jar 包中提供给业务代码调用。
	其基本原理是一个基于集中式配置的 jdbc datasource 实现，具有主备、读写分离、动态数据库配置等功能。
	
	中间件封装：
	中间件封装指的是独立一套系统出来，实现读写操作分离和数据库服务器连接的管理。
	中间件对业务服务器提供 SQL 兼容的协议，业务服务器无须自己进行读写分离。
	对于业务服务器来说，访问中间件和访问数据库没有区别，事实上在业务服务器看来，中间件就是一个数据库服务器。
	
	中间件封装特点：
	（1）能够支持多种编程语言，因为数据库中间件对业务服务器提供的是标准 SQL 接口。
    （2）数据库中间件要支持完整的 SQL 语法和数据库服务器的协议（例如，MySQL 客户端和服务器的连接协议），
	     实现比较复杂，细节特别多，很容易出现 bug，需要较长的时间才能稳定。
    （3）数据库中间件自己不执行真正的读写操作，但所有的数据库操作请求都要经过中间件，中间件的性能要求也很高。
    （4）数据库主从切换对业务服务器无感知，数据库中间件可以探测数据库服务器的主从状态。
	     例如，向某个测试表写入一条数据，成功的就是主机，失败的就是从机。
		 
	开源数据库中间件方案：
    （1）MySQL Proxy
	     MySQL 官方先是提供了 MySQL Proxy，但 MySQL Proxy 一直没有正式 GA
    （2）MySQL Router
	     现在 MySQL 官方推荐 MySQL Router。MySQL Router 的主要功能有读写分离、故障自动切换、负载均衡、连接池等
    （3）Atlas	
	     奇虎 360 公司也开源了自己的数据库中间件 Atlas，Atlas 是基于 MySQL Proxy 实现的

	应用场景：http://www.codes51.com/itwd/4270653.html
    
	
15、高性能数据库集群-方式二分库分表              分散数据库的存储压力

    常见的分散存储的方法“分库分表”，其中包括“分库”和“分表”两大类。
	
	业务分库
	业务分库指的是按照业务模块将数据分散到不同的数据库服务器。
	
	虽然业务分库能够分散存储和访问压力，但同时也带来了新的问题
	1.join 操作问题
	2. 事务问题
	3. 成本问题
	
	分表
	单表数据拆分有两种方式：垂直分表和水平分表
	
	垂直分表
	垂直分表适合将表中某些不常用且占了大量空间的列拆分出去。
	垂直分表引入的复杂性主要体现在表操作的数量要增加。
	
	水平分表
	水平分表适合表行数特别大的表，有的公司要求单表行数超过 5000 万就必须进行分表，这个数字可以作为参考，但并不是绝对标准，关键还是要看表的访问性能。
	对于一些比较复杂的表，可能超过 1000 万就要分表了；而对于一些简单的表，即使存储数据超过 1 亿行，也可以不分表。
	但不管怎样，当看到表的数据量达到千万级别时，作为架构师就要警觉起来，因为这很可能是架构的性能瓶颈或者隐患。
	
	水平分表相比垂直分表，会引入更多的复杂性，主要表现在下面几个方面：
	*路由
	水平分表后，某条数据具体属于哪个切分后的子表，需要增加路由算法进行计算，这个算法会引入一定的复杂性。
	常见的路由算法有：
	    范围路由
	    Hash 路由
	    配置路由
    *join 操作
	*count() 操作
	*order by 操作
	
	
16 高性能NoSQL

    关系数据库强大的SQL功能和ACID属性，使得关系数据库广泛应用于各式各样的系统中，但这并不意味着关系数据库是完美的，关系数据库存在以下缺点：        
	（1）关系数据库存储的是行记录，无法存储数据结构
    （2）关系数据库的schema扩展很不方便，也就是增加修改字段不方便
    （3）关系数据库在大数据场景下I/O较高
    （4）关系数据库的全文搜索功能比较弱
   
    针对上述问题，分别诞生了不同的NoSQL解决方案，这些方案与关系数据库相比，在某些应用场景下表现更好。
    NoSQL方案带来的优势，本质上是牺牲ACID中的某个或某几个特性，因此我们不能盲目迷信NoSQL是银弹，而应该将NoSQL作为SQL的一个有力补充。
    NoSQL 不是 No SQL，而是Not only SQL

    常见的NoSQL方案分为4类：
    K-V	存储：解决关系数据库无法存储数据结构的问题，以Redis为代表
    文档数据库：解决关系数据库强schema约束的问题，以MongoDB为代表
    列式数据库：解决关系数据库大数据场景下的I/O问题，以HBase为代表
    全文搜索引擎：解决关系数据库的全文搜索性能问题，以Elasticsearch为代表
	

17、高性能缓存架构

    虽然我们可以通过各种手段来提升存储系统的性能，但在某些复杂的业务场景下，单纯依靠存储系统的性能提升不够的，典型的场景有：
   （1）需要经过复杂运算后得出的数据，存储系统无能为力
   （2）读多写少的数据，存储系统有心无力
	缓存就是为了弥补存储系统在这些复杂业务场景下的不足，其基本原理是将可能重复使用的数据放到内存中，一次生成、多次使用，避免每次使用都去访问存储系统。
	
    缓存的架构设计要点：
	
   （1）缓存穿透
	缓存穿透是指缓存没有发挥作用，业务系统虽然去缓存查询数据，但缓存中没有数据，业务系统需要再次去存储系统查询数据。
   （2）缓存雪崩
	缓存雪崩是指当缓存失效（过期）后引起系统性能急剧下降的情况。
        缓存雪崩的常见解决方法有两种：更新锁机制和后台更新机制。
        a. 更新锁
        b. 后台更新
   （3）缓存热点
	虽然缓存系统本身的性能比较高，但对于一些特别热点的数据，如果大部分甚至所有的业务请求都命中同一份缓存数据，则这份数据所在的缓存服务器的压力也很大。
        缓存热点的解决方案就是复制多份缓存副本，将请求分散到多个缓存服务器上，减轻缓存热点导致的单台缓存服务器压力。
	缓存副本设计有一个细节需要注意，就是不同的缓存副本不要设置统一的过期时间，否则就会出现所有缓存副本同时生成同时失效的情况，从而引发缓存雪崩效应。
        正确的做法是设定一个过期时间范围，不同的缓存副本的过期时间是指定范围内的随机值。
		 

18、单服务器高性能模式：PPC 与 TPC

	高性能架构设计主要集中在两方面：
	（1）尽量提升单服务器的性能，将单服务器的性能发挥到极致。
	（2）如果单服务器无法支撑性能，设计服务器集群方案。
	
	架构设计决定了系统性能的上限，实现细节决定了系统性能的下限。
	
	单服务器高性能的关键之一就是服务器采取的并发模型，并发模型有如下两个关键设计点：
	（1）服务器如何管理连接。
	（2）服务器如何处理请求。
	以上两个设计点最终都和操作系统的I/O模型及进程模型相关：
	I/O模型：阻塞、非阻塞、同步、异步
	进程模型：单进程、多进程、多线程
	
	-----------------------------------------------------------------------------------------------------------------------------------------------------------
	分得清阻塞和非阻塞 以及 同步与异步，但就是搞不懂 阻塞和同步有啥不同，刚好知乎上有一个回答解开了我的困惑：
	作者：严肃
    链接：https://www.zhihu.com/question/19732473/answer/20851256
    来源：知乎
    著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

    1.同步与异步同步和异步关注的是消息通信机制 (synchronous communication/ asynchronous communication)
    所谓同步，就是在发出一个*调用*时，在没有得到结果之前，该*调用*就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由*调用者*主动等待这个*调用*的结果。
    而异步则是相反，*调用*在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。
	而是在*调用*发出后，*被调用者*通过状态、通知来通知调用者，或通过回调函数处理这个调用。
	典型的异步编程模型比如Node.js 
	举个通俗的例子：
	你打电话问书店老板有没有《分布式系统》这本书，如果是同步通信机制，书店老板会说，你稍等，”我查一下"，然后开始查啊查，
	等查好了（可能是5秒，也可能是一天）告诉你结果（返回结果）。
	而异步通信机制，书店老板直接告诉你我查一下啊，查好了打电话给你，然后直接挂电话了（不返回结果）。
	然后查好了，他会主动打电话给你。在这里老板通过“回电”这种方式来回调。
	2. 阻塞与非阻塞阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态.
	阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。
	非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。
	还是上面的例子，
	你打电话问书店老板有没有《分布式系统》这本书，你如果是阻塞式调用，你会一直把自己“挂起”，直到得到这本书有没有的结果，
	如果是非阻塞式调用，你不管老板有没有告诉你，你自己先一边去玩了， 当然你也要偶尔过几分钟check一下老板有没有返回结果。
	在这里阻塞与非阻塞与是否同步异步无关。跟老板通过什么方式回答你结果无关。
	-----------------------------------------------------------------------------------------------------------------------------------------------------------
	
    PPC
	PPC 是 Process Per Connection 的缩写，其含义是指每次有新的连接就新建一个进程去专门处理这个连接的请求，这是传统的 UNIX 网络服务器所采用的模型。
	PPC 模式实现简单，比较适合服务器的连接数没那么多的情况，例如数据库服务器。
	PPC 方案弊端：
	  fork 代价高
	  父子进程通信复杂
	  支持的并发连接数量有限
	
	TPC
	TPC 是 Thread Per Connection 的缩写，其含义是指每次有新的连接就新建一个线程去专门处理这个连接的请求。
	TPC 方案弊端：
	  创建线程虽然比创建进程代价低，但并不是没有代价，高并发时（例如每秒上万连接）还是有性能问题。
	  无须进程间通信，但是线程间的互斥和共享又引入了复杂度，可能一不小心就导致了死锁问题。
	  多线程会出现互相影响的情况，某个线程出现异常时，可能导致整个进程退出（例如内存越界）。
	  
	对比 PPC 和 TPC，总结来说，PPC稳定性高，PPC支持并发连接数高
	
	
19 单服务器高性能架构：Reactor 和 Proactor

    单服务器高性能的PPC 和 TPC，它们的优点都是实现简单，缺点是都无法支撑高并发的场景，Reactor 和 Proactor正是为此为生的。

    Reactor
    
    引入进程池/线程池（统称为资源池），实现资源复用，这样就不需要单独为每个连接创建进程/线程，而是创建一个资源池，将连接分配给资源池中的某个
    进程/线程来处理，处理完后进程/线程重新返回资源池等待下一个连接。这样，一个进程/线程就可以处理多个连接业务。

    一个进程/线程，一个连接的情况下，进程/线程可以采用“read-->业务处理-->write”的处理流程，如果当前连接没有数据可读，则进程就阻塞在read操作上。
    但是，如果是一个进程/线程，多个连接的情况下，如果进程阻塞在某个连接的read操作上，那么此时即便其他连接上有数据可读，进程/线程也无法去处理，
    很显然这样是无法做到高性能的。为了解决这个问题，引入I/O多路复用技术（https://www.zhihu.com/question/32163005）。

    I/O多路复用结合线程池，完美地解决了PPC 和 TPC的问题，而且“大神们”给它取了一个很牛的名字：Reactor。
    Reactor模式也叫Dispatcher模式，Dispatcher更加贴近模式本身含义，即I/O多路复用统一监听事件，收到事件后分配（Dispatch）给资源池中的某个进程/线程。

    Reactor模式的核心组成部分包括Reactor和资源池（进程池或线程池），其中Reactor负责监听和分配事件,资源池负责处理事件。
    Reactor模式的具体实现方案灵活多变，主要体现在：Reactor的数量可以变化;资源池中资源的数量可以变化。
    最终Reactor模式有三种典型的实现方案：
    单Reactor单进程/线程：只适用于业务处理非常快速的场景，目前比较著名的开源软件中使用单Reactor单进程/线程的是Redis
    单Reactor多线程：
    多Reactor多进程/线程：目前著名开源系统Nginx采用的是多Reactor多进程，Memecache和Netty采用的是多Reactor多线程

    Proactor

    Reactor是非阻塞同步网络模型，因为真正的read和send操作都需要用户进程同步操作。这里的“同步”指用户进程在执行read 和 send这类I/O操作的时候是
    同步的，如果把I/O操作改为异步就能够进一步提升性能，这就是异步网络模型Proactor。
    
    



    







